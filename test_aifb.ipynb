{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d1bc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/uu/thesis/convolution-matching/.venvconv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.6.\n"
     ]
    }
   ],
   "source": [
    "from GraphSummarizers.Coarsener.HeteroCoarsener import HeteroCoarsener\n",
    "from Datasets.NodeClassification.DBLP import DBLP\n",
    "from Datasets.NodeClassification.AIFB import AIFB\n",
    "from Datasets.NodeClassification.TestHetero import TestHeteroSmall, TestHeteroBig\n",
    "import importlib\n",
    "import torch\n",
    "from test_data_converter import dgl_to_pyg_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb3efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "aifb = AIFB()\n",
    "new_g = aifb.load_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaefccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start create H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/uu/thesis/convolution-matching/GraphSummarizers/Coarsener/HeteroCoarsener.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  degree = torch.tensor(self.node_degrees[etype][\"out\"]).to(device)\n",
      "/home/robin/uu/thesis/convolution-matching/GraphSummarizers/Coarsener/HeteroCoarsener.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  degree = torch.tensor(self.node_degrees[etype][\"in\"]).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created H 23.247557640075684\n",
      "start init costs\n",
      "stop init costs 3.739961624145508\n",
      "start lowest cost edges\n",
      "stop lowest cost edges 2.5494067668914795\n",
      "start select candidates\n",
      "stop select canidates 0.03641319274902344\n"
     ]
    }
   ],
   "source": [
    "new_g.nodes(\"Forschungsgebiete\")\n",
    "\n",
    "coarsener = HeteroCoarsener(None, new_g, 0.5)\n",
    "H = coarsener._create_h_spatial_rgcn(new_g)\n",
    "candidates = coarsener._select_candidates(coarsener._get_intersection(coarsener._get_rgcn_edges(H)))\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba7e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_graph, mapping_authors = coarsener._merge_nodes(new_g, \"Forschungsgebiete\", candidates[\"Forschungsgebiete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8757a771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robin/uu/thesis/convolution-matching/.venvconv/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:573: UserWarning: There exist type names in the 'HeteroData' object that contain double underscores '__' (e.g., 'Forschungsgebiete_ontology#name__Literal'). This may lead to unexpected behavior. To avoid any issues, ensure that your type names only contain single underscores.\n",
      "  warnings.warn(f\"There exist type names in the \"\n"
     ]
    }
   ],
   "source": [
    "original_data, o_x_dict, o_edge_index_dict, o_node_types, o_edge_types = dgl_to_pyg_input(new_g)\n",
    "\n",
    "coarsened_data, c_x_dict, c_edge_index_dict, c_node_types, c_edge_types = dgl_to_pyg_input(merged_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f40516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n",
      "Node types: ['Forschungsgebiete', 'Forschungsgruppen', 'Kooperationen', 'Personen', 'Projekte', 'Publikationen', '_Literal']\n",
      "Label node type: Personen\n",
      "Epoch 000 | Loss: 5.6058 | Train Acc: 0.1643\n",
      "Epoch 010 | Loss: 0.0926 | Train Acc: 0.9786\n",
      "Epoch 020 | Loss: 0.0351 | Train Acc: 0.9929\n",
      "Epoch 030 | Loss: 0.0114 | Train Acc: 1.0000\n",
      "Epoch 040 | Loss: 0.0046 | Train Acc: 1.0000\n",
      "\n",
      "✅ Test Accuracy on 'Personen' nodes: 0.8889\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data.rdf import AIFBDataset\n",
    "from Models.GNNs.HGCN import RGCN\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load AIFB dataset\n",
    "dataset = AIFBDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "# Check node types and label node type\n",
    "print(\"Node types:\", g.ntypes)\n",
    "print(\"Label node type:\", dataset.predict_category)  # should be 'Personen'\n",
    "#g = merged_graph\n",
    "label_ntype = dataset.predict_category  # 'Personen'\n",
    "labels = g.nodes[label_ntype].data['labels']\n",
    "train_mask = g.nodes[label_ntype].data['train_mask'].bool()\n",
    "num_classes = dataset.num_classes\n",
    "test_mask = g.nodes[label_ntype].data['test_mask'].to(torch.bool)\n",
    "# Define embedding size\n",
    "embed_size = 16\n",
    "#g = merged_graph\n",
    "# Create trainable input embeddings for all node types\n",
    "node_embeds = nn.ModuleDict({\n",
    "    ntype: nn.Embedding(g.num_nodes(ntype), embed_size)\n",
    "    for ntype in g.ntypes\n",
    "})\n",
    "\n",
    "# Instantiate model\n",
    "model = RGCN(in_feats=embed_size, hidden_feats=32, out_feats=num_classes, etypes=g.etypes)\n",
    "\n",
    "# Move to device if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "node_embeds = node_embeds.to(device)\n",
    "labels = labels.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "g = g.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(node_embeds.parameters()), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    \n",
    "    inputs = {ntype: node_embeds[ntype].weight for ntype in g.ntypes}\n",
    "    logits = model(g, inputs)[label_ntype]\n",
    "    \n",
    "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = logits.argmax(dim=1)\n",
    "    acc = accuracy_score(labels[train_mask].cpu(), pred[train_mask].cpu())\n",
    "    if epoch % 10 == 0:\n",
    "        # Print training loss and accuracy every 10 epochs\n",
    "        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f} | Train Acc: {acc:.4f}\")\n",
    "\n",
    "test_mask = g.nodes[label_ntype].data['test_mask'].to(torch.bool)\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = {ntype: node_embeds[ntype].weight for ntype in g.ntypes}\n",
    "    logits = model(g, inputs)[label_ntype]\n",
    "    pred = logits.argmax(dim=1)\n",
    "\n",
    "    test_acc = accuracy_score(labels[test_mask].cpu(), pred[test_mask].cpu())\n",
    "    print(f\"\\n✅ Test Accuracy on '{label_ntype}' nodes: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be21e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Test Accuracy on 'Personen' nodes: 0.8889\n"
     ]
    }
   ],
   "source": [
    "test_mask = g.nodes[label_ntype].data['test_mask'].to(torch.bool)\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = {ntype: node_embeds[ntype].weight for ntype in g.ntypes}\n",
    "    logits = model(g, inputs)[label_ntype]\n",
    "    pred = logits.argmax(dim=1)\n",
    "\n",
    "    test_acc = accuracy_score(labels[test_mask].cpu(), pred[test_mask].cpu())\n",
    "    print(f\"\\n✅ Test Accuracy on '{label_ntype}' nodes: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvconv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
